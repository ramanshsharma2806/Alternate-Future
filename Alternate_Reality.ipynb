{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alternate_Reality",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramanshsharma2806/Alternate-Reality/blob/master/Alternate_Reality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zITuJAv0zX3g"
      },
      "source": [
        "#**ALTERNATE REALITY**\n",
        "\n",
        "### **Description**\n",
        "\n",
        "---\n",
        "\n",
        "This is a project that I am working on to apply my newfound skills of Recurrent Neural Networks and Natural Language Processing. This project deals with **text generation** using LSTM RNN's.\n",
        "\n",
        "\n",
        "### **Motivation**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "I lived in New York City from 2014 to 2018. In the American education system, students write out different things (essays, poems, research papers, op-eds, etc.) on a daily basis.\n",
        "\n",
        "Throughout my time at *The Bronx High School of Science*, I was trained in the art of scientific thinking! I had to write daily homeworks for my english class, most of which I typed up in Google docs. I also wrote numerous research papers for my english and history classes, some of which were well above **20 pages**. All of these texts are my creation. My own piece in the world of words and sentences.\n",
        "\n",
        "When I had to leave *New York City* in the middle of my senior year, I was devastated beyond narration. It was the single most horrifying experience of my life. I was detached from everything I belonged to and stood for (kind of like Thor if you think about it) and banished away. \n",
        "\n",
        "Ever since then, I have not been able to think like I used to be able to. I read text, but I am not critically thinking of it, not finding literary and rhetorical devices that the author used to set a scene, or show the development of a character.\n",
        "\n",
        "And so I turned to **Neural Networks** to help me out. By using **Python**, **Keras**, and **LSTM**, I will be able to create a *Recurrent Neural Network* for language modeling and sample new text written in my style."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iokuQUsJI2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cada1c0-4988-4675-a2d9-58e5a99a2624"
      },
      "source": [
        "\"\"\"\n",
        "mounting the google drive to use text data and to clone GItHub repositories\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJHeR_2ESIAf"
      },
      "source": [
        "\"\"\"\n",
        "important libraries imported\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "import os, io, sys, random, time, pprint\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import one_hot\n",
        "from tensorflow.keras.callbacks import LambdaCallback, LearningRateScheduler\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Activation, Dropout, Input, Lambda, Reshape, Masking, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam, Adamax, Adagrad, RMSprop, Adadelta, SGD\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.utils import to_categorical, plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI6ZPYi-Yz8u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bae24f5-4a14-4473-cc3e-eaeffadf03e2"
      },
      "source": [
        "\"\"\"\n",
        "making sure tensorflow's version2 is used in this notebook\n",
        "\"\"\"\n",
        "\n",
        "assert int(tf.__version__[0]) == 2, 'Uh oh, Tensorflow\\' version is not 2 right now. Please fix this first by changing runtime' \n",
        "\n",
        "print(\"Tensorflow version: \" + tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKm3VjU9Sv0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05d73d94-acac-4093-da01-4cd2909b91e8"
      },
      "source": [
        "\"\"\"\n",
        "testing if connected to TPU and/or GPU\n",
        "\"\"\"\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('Not connected to a TPU runtime.')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('Connected to TPU.\\n\\nTPU address is', tpu_address)\n",
        "\n",
        "  with tf.compat.v1.Session((tpu_address)) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)\n",
        "\n",
        "if tf.test.gpu_device_name() == '':\n",
        "  print('\\n\\nNot connected to a GPU runtime.')\n",
        "else:\n",
        "  print('\\n\\nConnected to GPU: ' + tf.test.gpu_device_name())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Connected to TPU.\n",
            "\n",
            "TPU address is grpc://10.84.56.250:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 8869462608345730394),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -5692267719995901759),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -6185421050533549910),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 8145699456829971494),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -8776359194660724298),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -2738699687259503892),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 424102068381025835),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -6604371756709645568),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -7959627977808719268),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 5403933190210585122),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8840701031394454306)]\n",
            "\n",
            "\n",
            "Not connected to a GPU runtime.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83PeaGO82CB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41256b72-a2c0-4440-b5ad-5ef5afbe5f30"
      },
      "source": [
        "\"\"\"\n",
        "cleaning the data and forming the examples\n",
        "\"\"\"\n",
        "\n",
        "path = \"/content/drive/My Drive/Alternate-Reality/folder/text_data/merged.txt\"\n",
        "\n",
        "with io.open(path, encoding='utf-8') as corpus:\n",
        "    text = corpus.read()\n",
        "\n",
        "LENGTH = len(text)\n",
        "Tx = 11 # length of each example (characters)\n",
        "\n",
        "vocab = sorted(set(list(text))) # list (a set actually) of all the characters in the corpus\n",
        "char_to_indices = dict((ch, idx) for idx, ch in enumerate(vocab))\n",
        "index_to_char = dict((idx, ch) for idx, ch in enumerate(vocab))\n",
        "\n",
        "# pretty much temporary variables just for the sake of splitting the huge corpus\n",
        "sentences = [] # X\n",
        "mapped_chars = [] # Y\n",
        "\n",
        "step = 2\n",
        "\n",
        "for i in range(0, LENGTH - Tx, step):\n",
        "    temp_text = text[i: i+Tx]\n",
        "    sentences.append(temp_text[:-1])\n",
        "    mapped_chars.append(temp_text[-1])\n",
        "\n",
        "m = len(sentences)\n",
        "\n",
        "X = np.zeros((m, Tx - 1, len(vocab)))\n",
        "Y = np.zeros((m, len(vocab)))\n",
        "\n",
        "for i, example in enumerate(sentences):\n",
        "    X[i, :, :] = one_hot([char_to_indices[ch] for ch in example], depth=len(vocab))\n",
        "    Y[i, :] = one_hot(char_to_indices[mapped_chars[i]], depth=len(vocab))\n",
        "\n",
        "# a nuisance is fixed by turning X and Y into numpy arrays\n",
        "X = np.asarray(X)\n",
        "Y = np.asarray(Y)\n",
        "\n",
        "#==============printing data dimesions=========================================\n",
        "print(f\"Length of corpus: {LENGTH}\")\n",
        "print(f\"X.shape = {X.shape}\")\n",
        "print(f\"Y.shape = {Y.shape}\")\n",
        "print(f\"Number of examples: {m}\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of corpus: 229570\n",
            "X.shape = (114780, 10, 96)\n",
            "Y.shape = (114780, 96)\n",
            "Number of examples: 114780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kzEifE0OT_P"
      },
      "source": [
        "\"\"\"\n",
        "read the function docstring below\n",
        "\"\"\"\n",
        "\n",
        "def get_example(index=None):\n",
        "    \"\"\"\n",
        "    retrieves the example at index position in X is index is passed, otherwise random example is obtained\n",
        "    :param index: index of example desired to be retrieved\n",
        "    :return: string of text\n",
        "    \"\"\"\n",
        "\n",
        "    if index is None:\n",
        "        index = np.random.randint(low=0, high=m)\n",
        "\n",
        "    curr_x = [index_to_char[idx] for idx in np.argmax(X[index, :, :], axis=1)]\n",
        "    curr_y = index_to_char[np.argmax(Y[index, :])]\n",
        "\n",
        "    x_y = (''.join(curr_x), curr_y)\n",
        "\n",
        "    return x_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpYgE7ygSLTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4b4403-33d1-4b1f-be1f-3e0c7e257424"
      },
      "source": [
        "\"\"\"\n",
        "testing a single example and the time it took to retrieve it\n",
        "\"\"\"\n",
        "\n",
        "start = time.process_time()\n",
        "example = get_example()\n",
        "end = time.process_time()\n",
        "\n",
        "print(f\"Sample X: {example[0]}\\nCorresponding Y: {example[1]}\")\n",
        "print(f\"\\nTime taken for acquiring this example: {end - start} seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample X: lity at al\n",
            "Corresponding Y: l\n",
            "\n",
            "Time taken for acquiring this example: 0.000509900000004393 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPLZQqNSwuah"
      },
      "source": [
        "\"\"\"\n",
        "network architecture creation\n",
        "model creation\n",
        "plot_model allows me to see what my neural network looks like\n",
        "\"\"\"\n",
        "\n",
        "def Ram_Says(Tx, vocab, output_length):\n",
        "  # network architecture LSTM -> Dropout -> Reshape -> LSTM -> Dropout -> Dense\n",
        "\n",
        "  X = Input(shape=(Tx, len(vocab)), name='X')\n",
        "  \n",
        "  a = Bidirectional(LSTM(units=output_length, activation='tanh', return_sequences=True, dtype='float32', name=f'lstm_1'))((X))\n",
        "#   a = Dropout(rate=0.4, name=f'dropout_1')(a)\n",
        "\n",
        "  a = Bidirectional(LSTM(units=output_length, activation='tanh', dtype='float32', name=f'lstm_2'))(a)\n",
        "#   a = Dropout(rate=0.4, name=f'dropout_2')(a)\n",
        "\n",
        "  out = Dense(units=len(vocab), activation='softmax', name=f'dense')(a)\n",
        "    \n",
        "  model = Model(inputs=[X], outputs=out, name='Ram')\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GTikSyoerWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "967c9111-cacc-482e-cfbb-c149138ab4df"
      },
      "source": [
        "\"\"\"\n",
        "creating the model and the summary of it\n",
        "\"\"\"\n",
        "#====================Creating important variables===============================\n",
        "n_a = 32 # number of hidden state dimensions for each LSTM cell\n",
        "\n",
        "a0 = np.zeros((m, n_a))\n",
        "c0 = np.zeros((m, n_a))\n",
        "#===============================================================================\n",
        "\n",
        "model = Ram_Says(Tx=Tx - 1, vocab=vocab, output_length=n_a)\n",
        "\n",
        "plot_model(model, to_file='/content/drive/My Drive/Alternate-Reality/nn_graph.png')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Ram\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "X (InputLayer)               [(None, 10, 96)]          0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 10, 64)            33024     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 96)                6240      \n",
            "=================================================================\n",
            "Total params: 64,096\n",
            "Trainable params: 64,096\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym_8cL998Ybq"
      },
      "source": [
        "\"\"\"\n",
        "picking the best learning rate\n",
        "\"\"\"\n",
        "\n",
        "lr_schedule = LearningRateScheduler(\n",
        "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "history = model.fit(X, Y, epochs=100, callbacks=[lr_schedule])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncNQ8z3o8prn"
      },
      "source": [
        "# seeing which learning rate has the lowest Huber loss\n",
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-8, 1e-4, 0, 30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFzkBWLkMA94",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4445f815-3e7a-479d-c101-86050cd6818f"
      },
      "source": [
        "\"\"\"\n",
        "configuring optimizations for the model\n",
        "fitting the model\n",
        "\"\"\"\n",
        "\n",
        "tf.keras.backend.clear_session() # clearing the model weights from previous run\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = Adadelta(learning_rate=learning_rate)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 512\n",
        "\n",
        "model.fit([X], Y, batch_size=batch_size, epochs=400)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "57/57 [==============================] - 27s 482ms/step - loss: 4.5649 - accuracy: 0.0074\n",
            "Epoch 2/100\n",
            "42/57 [=====================>........] - ETA: 7s - loss: 4.5640 - accuracy: 0.0087"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXexPfExcpNe"
      },
      "source": [
        "\"\"\"\n",
        "filepath at which my trained model will reside\n",
        "\"\"\"\n",
        "\n",
        "filepath = '/content/drive/My Drive/Alternate-Reality/Ram_Says_Trained_Model.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnrScYNaRlFr"
      },
      "source": [
        "\"\"\"\n",
        "this code takes care of saving the new model only if its accuracy is better than\n",
        "that of the last model\n",
        "\"\"\"\n",
        "\n",
        "if os.path.exists(filepath):\n",
        "  prev_model = load_model(filepath)\n",
        "  prev_acc = prev_model.evaluate([X, a0, c0], Y, verbose=0)[1]\n",
        "  curr_acc = model.evaluate([X, a0, c0], Y, verbose=0)[1]\n",
        "  if curr_acc > prev_acc:\n",
        "    print(\"There was a previous model saved.\")\n",
        "    print(f\"Previous accuracy: {round(prev_acc*100, 2)}%\")\n",
        "    print(f\"Current accuracy: {round(curr_acc*100, 2)}%\")\n",
        "    model.save(filepath)\n",
        "    print('New model is saved.')\n",
        "  else:\n",
        "    print(f\"Previous accuracy: {round(prev_acc*100, 2)}%\")\n",
        "    print(f\"Current accuracy: {round(curr_acc*100, 2)}%\")\n",
        "    print('Old model is kept.')\n",
        "else: # if this is the first time saving the model\n",
        "  model.save(filepath)\n",
        "  print('First time model is saved.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HojRFbuhdgze"
      },
      "source": [
        "\"\"\"\n",
        "loading the model for sampling\n",
        "\"\"\"\n",
        "\n",
        "Ram_says = load_model(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw-XXtYuYJ-8"
      },
      "source": [
        "\"\"\"\n",
        "testing the accuracy of the model on X and Y\n",
        "\"\"\"\n",
        "\n",
        "accuracy = Ram_says.evaluate([X, a0, c0], Y, verbose=0)[1]\n",
        "print(f\"Accuracy on the training set: {round(accuracy*100, 2)}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHJwSspvMVkp"
      },
      "source": [
        "\"\"\"\n",
        "text sampling time\n",
        "\"\"\"\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def generate_output():\n",
        "      diversity = random.choice([0.2, 0.5, 0.7, 1.0, 1.2, 1.4])\n",
        "      diversity = 0.2\n",
        "      print(f'Diversity: {diversity}\\n')\n",
        "      generated = ''\n",
        "      sentence = input('Your text: ')\n",
        "      generated += sentence\n",
        "      if len(sentence) > 10:\n",
        "        sentence = sentence[:10]\n",
        "      elif len(sentence) < 10:\n",
        "        rem = 10 - len(sentence)\n",
        "        sentence += ' ' * rem\n",
        "      sys.stdout.write(generated + ' ')\n",
        "      a0 = np.zeros((1, n_a))\n",
        "      c0 = np.zeros((1, n_a))\n",
        "      sys.stdout.write(sentence)\n",
        "      for i in range(1000):\n",
        "          x_pred = np.zeros((1, Tx-1, len(vocab)))\n",
        "          for t, char in enumerate(sentence):\n",
        "              if char != '0':\n",
        "                  x_pred[0, t, char_to_indices[char]] = 1.\n",
        "          preds = Ram_says.predict([x_pred, a0, c0], verbose=0)[0]\n",
        "          next_index = sample(preds, temperature = 1.0)\n",
        "          next_char = index_to_char[next_index]\n",
        "\n",
        "          generated += next_char\n",
        "          sentence = sentence[1:] + next_char\n",
        "\n",
        "          sys.stdout.write(next_char)\n",
        "          sys.stdout.flush()\n",
        "\n",
        "          if next_char == '\\n':\n",
        "              print('\\n')\n",
        "          elif next_char == '\\t':\n",
        "              print('\\t')\n",
        "\n",
        "generate_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_orRDcEbn3i"
      },
      "source": [
        "# I will be placing the model's generated text below for record."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEeSqIBI8nuH"
      },
      "source": [
        " > \"My name is Ramansh Sharma My name is the public control considered to fut tell overt of a decide the world to life people real and massive really came to congres to be streated it could have ingarding the world many that estabe by nugues and could have been guvern for the Soligition, purched that remamplogr prices repective independence in 1982. Bech of 1980ided to social and enjoyable capting the sent a see that her seperones in Am\" - Ram_says\n",
        "\n",
        "Pretty good for a first try for a character level model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1yBAYAUakgJ"
      },
      "source": [
        "> My name is Ram My name is for the fight not started with a being at left the sade but the colonists clear of the Dept-A spondin surmerity, Konusansingtond that in the US and CIA port and scange and industed the Cold War and Congress in Depertmant in reace in the different id on the eneming American relations going to see servions. He also failed in his becuuse to the ready the Ford she end and commercesvestromes to onder the shooked a protects the treaty proved my team America in aid of the new that her strect of phy incrusing and of the pagome, he hading the didrition in 1982. After their visto want in the Cold War which movern of the fen his “In and wenter for their marking of confisens than his prorecive in front of a contriluting as a \"confid and the Office of Economic Opportunity. He also failed in his fail w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGSeb-T2b0FY"
      },
      "source": [
        "> Thor is the king Thor is the rare to be some known as the enemonity of Congress, the meint in the Cold War when Chine with them. I was also high domination which dickins of Curness, he will be a beation….ther would reduce the decision of appressed nor the increased communist against controlles. Perretimmert. Itay of nuclas they gave he was a tork the side and very impossing this him as a facutive promest it be a stay a and fack as the anities and the EPand and being people white Sinally sochiets. He did not convered congresity. \n",
        "\n",
        "\n",
        "> o show he was the niting to the 1987 in are income taxes. Truean aid to the child of cotting in country, this be mistaky was allice the new that were because Opeaa Act goush in the Cold War and Congress dissided on I came to that felt me to event, and the INation He was was a Soviet troops,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLcz3Dl327C5"
      },
      "source": [
        "> The The                                 Date-10foce deneed to ave the police of the sent to be some known as “To loon duberd many as it is to New York, to his domestic oil for a long of the weap in Congress she had ease and ensore considerable spending neges and cered to confinced the not on that is a senter aftarity, and a communist confidend ming the enemonity of Congress, complelated to make me to ausheres decart did not prife to meacunion of the Indians, if the stopled. And order to be the same that I am good family defense does money starting ut from America. a recatted to the 1972 Nair ance me to eventle, to stay the cares and even Dieanation, even to geter from the British other trages in Robard on New Yer proved a coffitted them in 1975, up they wanted to raised her free that they will be jasunang but was is the mind end hand of the part endere to the money starting under President during the reader to the side because Opea which states who arm diresten to whith with whith security plannerd "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFoEB1ni3egY"
      },
      "source": [
        "> He He                 O the the mare the contere. It I say the other mary broke even maied. He under the dreamsed, and offectal stayd hims thrir mainiff Uaration with Britas program, but affairenn), she mover worker whose poriot. In from there shiet from Congress. This made colonists and I could not steention of the phase good seve was bring some sy wifher to be his was the first time I haugh  a chulgud a few hap ancelest of the American army. It was the ended on economy suld will be one of the Crime 37 20pacterd History 34, no. 3 (1933): 426. Jule I could lead recrios which shors on you b in American of the min-Contrass right thing the Ridhtn Lassullied (the his deenyd. The president orning the Notthis a. Mricare the cancer of the tamentation brings ho selities, gave not lother on the slave  and memintide this farion of the second Goor of Congresst and sted und beht aid to expent led and even what in the show down I decided to treat meaning as a cresturfiged the tarre of station for priven and the"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkHjVdj27TPq"
      },
      "source": [
        "> Yo what's up Yo what's with he bearson suchearing them war sighed and cotten and from there shipt was not ever shatsh poritic let sighed to apnounces that while, break that was fevely betrefilds, which in treaty for as it was called, but alwority, the 1981. about from their busing to be a oping stregated of success, which sad be that the prisented red cating the was in engrother on the spended in Janee and South, a posens thatn at the strests against seberild of the British or because I learnt to mored insore the economy attocies in the Aderime not a spoech are, suppled that even the something, nother had ever libertoratimy asting, and he solust and maintasion dediried to move heam with and show him that it in the spack in the dain the Areas and Hanim and programs but a carred the second Goed of U.S. planege in protent a mandine that America in front of me. Mhicret confised, deechow makereasing. So Ih B. pomely of enconry completed fur the read of believe which was it provest like a distrupilic. a d fent, me"
      ]
    }
  ]
}